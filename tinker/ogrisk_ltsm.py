# -*- coding: utf-8 -*-
"""OGRISK_LTSM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hKssxts3oDupOytHYulCCDffV1EWbrOD
"""

import json
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM

# Load data from JSON file
with open('/home/nick/acsus/out-of-gas-ml/features_and_labels.json', 'r') as f:
    data = json.load(f)

# Define a function to pad the flow vectors
def pad_flow_vectors(flow_vectors, max_length):
    padded_vectors = []
    for vector in flow_vectors:
        # Pad with zeros if the vector length is less than max_length
        if len(vector) < max_length:
            padded_vector = np.pad(vector, (0, max_length - len(vector)), mode='constant')
        else:
            padded_vector = vector
        padded_vectors.append(padded_vector)
    return padded_vectors

# Find the maximum length of flow vectors
max_length = max(len(entry['flow_vector']) for entry in data)

# Extract features and labels
X = []
y = []

for entry in data:
    flow_vectors = entry['flow_vector']

    # Pad the flow vectors to ensure uniform length
    padded_vectors = pad_flow_vectors(flow_vectors, max_length)

    # Convert flow vectors to NumPy array
    code_vector = np.array(padded_vectors)

    X.append(code_vector)
    y.append(entry['label'])

X = np.array(X)
y = np.array(y)


# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data (optional but recommended)
X_train = X_train / np.max(X_train)
X_val = X_val / np.max(X_val)





# Define the model
model = Sequential([
    Dense(64, activation='tanh', input_shape=(X_train.shape[1],)),
    Dense(32, activation='tanh'),
    Dense(16, activation='tanh'),
    Dense(3, activation='softmax') # Final dense layer with 3 units for 3 classes
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))





# Predict labels for validation set
y_pred = model.predict(X_val)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate performance metrics
f1 = f1_score(y_val, y_pred_classes, average='weighted')
precision = precision_score(y_val, y_pred_classes, average='weighted')
recall = recall_score(y_val, y_pred_classes, average='weighted')
accuracy = accuracy_score(y_val, y_pred_classes)

print("F1 Score:", f1)
print("Precision:", precision)
print("Recall:", recall)
print("Accuracy:", accuracy)




import matplotlib.pyplot as plt

# Plot training and validation errors
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()